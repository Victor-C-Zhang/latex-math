\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\title{481 - Homework 12}
\author{Victor Zhang}
\date{December 9, 2020}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{graphicx}
% \usepackage{changepage}
\usepackage{amssymb}
\usepackage{xfrac}
% \usepackage{bm}
% \usepackage{empheq}\
\usepackage{dirtytalk}

\newcommand{\contra}{\raisebox{\depth}{\#}}

\newenvironment{myindentpar}[1]
  {\begin{list}{}
          {\setlength{\leftmargin}{#1}}
          \item[]
  }
  {\end{list}}

\pagestyle{empty}

\begin{document}

\maketitle
% \begin{center}
% {\huge Econ 482 \hspace{0.5cm} HW 3}\
% {\Large \textbf{Victor Zhang}}\
% {\Large February 18, 2020}
% \end{center}

\section*{14.17}
\begin{equation*}
\begin{split}
\sum\limits^n [y_i - (\hat{\alpha} + \hat{\beta}x_i)]^2 &= \sum\limits^n [y_i-\overline{y} + \hat{\beta}\overline{x} -\hat{\beta}x_i]^2\\
&= \sum\limits^n [(y_i-\overline{y}) - \hat{\beta}(x_i-\overline{x})]^2\\
&= \sum\limits^n [(y_i-\overline{y})^2 - 2\hat{\beta}(y_i-\overline{y})(x_i-\overline{x}) + \hat{\beta}^2(x_i-\overline{x})^2]\\
&= S_{yy} - 2\hat{\beta}S_{xy} + \hat{\beta}^2S_{xx}\\
&= S_{yy} -\frac{2S_{xy}^2}{S_{xx}} + \frac{S_{xy}^2}{S_{xx}}\\
&= S_{yy} - \hat{\beta}S_{xy} \; \Box
\end{split}
\end{equation*}

\section*{14.18}
\subsection*{14.18.1}
We use the fact $\frac{n\hat{\sigma}^2}{\sigma^2} \sim \chi^2_{n-2}$.
$$E[\hat{\sigma}^2] = \frac{\sigma^2}{n} E[\chi^2_{n-2}] = \frac{n-2}{n}\sigma^2 \neq \sigma^2 \;\Box$$
\subsection*{14.18.2}
Similarly,
$$E\left[\frac{n}{n-2}\hat{\sigma}^2\right] = \frac{n}{n-2} E[\hat{\sigma}^2] = \frac{n}{n-2}\frac{n-2}{n}\sigma^2 = \sigma^2 \;\Box$$

\section*{14.19}
With the standard error adjustment \say{baked into} $s_e$, we do not need an explicit $\sqrt{\frac{n-2}{n}}$ adjustment.
$$t = \frac{\hat{\beta}-\beta}{s_e/\sqrt{S_{xx}}}$$
$$\hat{\beta} - t_{\alpha/2,n-2}\frac{s_e}{\sqrt{S_{xx}}} < \beta < \hat{\beta} + t_{\alpha/2,n-2}\frac{s_e}{\sqrt{S_{xx}}} \;\Box$$

\section*{14.20}
\subsection*{14.20.1}
Under normal regression assumption, $\hat{\beta} = \frac{S_{xy}}{S_{xx}}$, $\hat{\alpha} = \overline{Y} - \hat{\beta}\overline{x}$. Then
\begin{equation*}
\begin{split}
\hat{\alpha} &= \overline{Y} - \frac{\sum (Y_i-\overline{Y})(x_i-\overline{x})}{S_{xx}}\overline{x}\\
&= \overline{Y} - \frac{\sum Y_i(x_i-\overline{x})\overline{x}}{S_{xx}}\\
&= \frac{1}{S_{xx}}\sum \left[\frac{S_{xx}\overline{Y}}{n} +\overline{x}^2Y_i - \overline{x}x_iY_i \right]\\
&= \frac{1}{S_{xx}}\sum \left[\frac{S_{xx}Y_i}{n} +\overline{x}^2Y_i - \overline{x}x_iY_i \right]\\
&= \sum \left[\frac{S_{xx} + n\overline{x}^2 - n\overline{x}x_i}{nS_{xx}}\right]Y_i \; \Box
\end{split}
\end{equation*}
\subsection*{14.20.2}
Under normal regression assumption, $\frac{S_{xx} + n\overline{x}^2 - \overline{x}x_i}{nS_{xx}}$ is a constant. Then $\hat{A}$ is the sum of $n$ independent Normal variables, so is Normal.
$$E[\hat{A}] = E[\overline{Y}-\hat{\beta}\overline{x}] = E\left[\frac{\sum Y_i}{n}\right] - \overline{x}E[\hat{\beta}] = \frac{1}{n}\sum (\alpha + \beta x_i) - \overline{x}\beta = \alpha$$
By homoskedasticity assumption, $\mathrm{var}(Y_i) = \sigma^2$.
\begin{equation*}
\begin{split}
\mathrm{var}(\hat{A}) &= \mathrm{var}\left(\sum \left[\frac{S_{xx} + n\overline{x}^2 - n\overline{x}x_i}{nS_{xx}}\right]Y_i\right)\\
&= \sum \left[\frac{S_{xx} + n\overline{x}^2 - n\overline{x}x_i}{nS_{xx}}\right]^2 \mathrm{var}(Y_i)\\
&= \sum \left[\frac{S_{xx} + n\overline{x}(\overline{x}-x_i)}{nS_{xx}}\right]^2 \sigma^2\\
&= \sigma^2 \sum \frac{S_{xx}^2 + 2S_{xx}n\overline{x}(\overline{x}-x_i)+n^2\overline{x}^2(x_i-\overline{x})^2}{n^2S_{xx}^2}\\
&= \sigma^2 \left(\frac{1}{n} + \frac{n^2\overline{x}^2 S_{xx}}{n^2 S_{xx}^2}\right)\\
&= \frac{(S_{xx}+n\overline{x}^2)\sigma^2}{nS_{xx}} \;\Box
\end{split}
\end{equation*}

\section*{14.21}
$$\mathrm{cov}(\hat{A},\hat{B}) = \mathrm{cov}(\overline{Y}-\hat{\beta}\overline{x}, \hat{\beta}) = \mathrm{cov}(\overline{Y},\hat{\beta}) - \overline{x}\mathrm{var}(\hat{\beta}) = - \frac{\overline{x}}{S_{xx}^2}\mathrm{var}(\sum Y_i(x_i-\overline{x})) = - \frac{\overline{x}}{S_{xx}^2}\sum (x_i-\overline{x})^2\sigma^2 = - \frac{\overline{x}}{S_{xx}}\sigma^2 \; \Box$$

\section*{14.22}
$\hat{A} \sim N(\alpha, \frac{(S_{xx}+n\overline{x}^2)\sigma^2}{nS_{xx}})$ so
$$\frac{\hat{\alpha}- \alpha}{\sqrt{\frac{(S_{xx}+n\overline{x}^2)\sigma^2}{nS_{xx}}}} = \frac{(\hat{\alpha}- \alpha)\sqrt{nS_{xx}}}{\sigma\sqrt{S_{xx}+n\overline{x}^2}} \sim Z$$
Since $\frac{n\hat{\sigma}^2}{\sigma^2} \sim \chi^2_{n-2}$, we may write
$$\frac{\frac{(\hat{\alpha}- \alpha)\sqrt{nS_{xx}}}{\sigma\sqrt{S_{xx}+n\overline{x}^2}}}{\sqrt{\sfrac{\frac{n\hat{\sigma}^2}{\sigma^2}}{(n-2)}}} = \frac{(\hat{\alpha}- \alpha)\sqrt{(n-2)S_{xx}}}{\hat{\sigma}\sqrt{S_{xx}+n\overline{x}^2}} \sim \frac{Z}{\sqrt{\chi^2_{n-2}/(n-2)}} = t_{n-2} \;\Box$$

\section*{14.23}
$\hat{Y}_0 = \hat{A} + \hat{B}x_0 = \overline{Y} - \hat{\beta}\overline{x} + \hat{\beta}x_0 = \overline{Y} + \hat{\beta}(x_0-\overline{x})$ is the sum of 2 independent Normal variables, so is Normal.
$$E[\hat{Y}_0] = E[\hat{A}+\hat{B}x_0] = \alpha + \beta x_0 = \mu_{Y|x_0}$$
$$\mathrm{var}(\hat{Y}_0) = \mathrm{var}(\hat{A}) + 2x_0\mathrm{cov}(\hat{A},\hat{B}) + x_0^2\mathrm{var}(\hat{B}) = \frac{(S_{xx}+n\overline{x}^2)\sigma^2}{nS_{xx}} - \frac{2x_0\overline{x}}{S_{xx}}\sigma^2 + \frac{\sigma^2}{S_{xx}} = \sigma^2\left(\frac{1}{n} + \frac{(x_0-\overline{x})^2}{S_{xx}}\right)$$
Similarly to the proof of 14.22,
$$\frac{(\hat{y}_0-\mu_{Y|x_0})\sqrt{n}}{\sigma \sqrt{1+\frac{n(x_0-\overline{x})^2}{S_{xx}}}} \sim Z$$
so
$$\frac{\frac{(\hat{y}_0-\mu_{Y|x_0})\sqrt{n}}{\sigma \sqrt{1+\frac{n(x_0-\overline{x})^2}{S_{xx}}}}}{\sqrt{\sfrac{\frac{n\hat{\sigma}^2}{\sigma^2}}{(n-2)}}} = \frac{(\hat{y}_0-\mu_{Y|x_0})\sqrt{n-2}}{\hat{\sigma} \sqrt{1+\frac{n(x_0-\overline{x})^2}{S_{xx}}}} \sim \frac{Z}{\sqrt{\chi^2_{n-2}/(n-2)}} = t_{n-2} \; \Box$$

\section*{14.24}
From 14.23 it follows immediately that
$$\hat{y}_0 - \frac{\hat{\sigma} \sqrt{1+\frac{n(x_0-\overline{x})^2}{S_{xx}}}}{\sqrt{n-2}}t_{\alpha/2,n-2} < \mu_{Y|x_0} < \hat{y}_0 + \frac{\hat{\sigma} \sqrt{1+\frac{n(x_0-\overline{x})^2}{S_{xx}}}}{\sqrt{n-2}}t_{\alpha/2,n-2}$$
is a $(1-\alpha)$ confidence interval for $\mu_{Y|x_0}$ $\Box$

\section*{14.25}
From 14.23 we recognize $\hat{A} + \hat{B}x_0 = \hat{Y_0}$. This is distributed $N(\alpha+\beta x_0, \sigma^2\left(\frac{1}{n} + \frac{(x_0-\overline{x})^2}{S_{xx}}\right))$. $Y_0 \sim N(\alpha + \beta x_0, \sigma^2)$. Thus $Y_0 - \hat{Y}_0 \sim N(0, \sigma^2 + \sigma^2\left(\frac{1}{n} + \frac{(x_0-\overline{x})^2}{S_{xx}}\right)) = N(0, \sigma^2\left(1 + \frac{1}{n} + \frac{(x_0-\overline{x})^2}{S_{xx}}\right))$. It follows from a very similar derivation as 14.23 that
$$\frac{\frac{(y_0-(\hat{\alpha}+\hat{\beta}x_0))\sqrt{n}}{\sigma \sqrt{1 + n +\frac{n(x_0-\overline{x})^2}{S_{xx}}}}}{\sqrt{\sfrac{\frac{n\hat{\sigma}^2}{\sigma^2}}{(n-2)}}} = \frac{(y_0-(\hat{\alpha}+\hat{\beta}x_0))\sqrt{n-2}}{\hat{\sigma} \sqrt{1+n+\frac{n(x_0-\overline{x})^2}{S_{xx}}}} \sim \frac{Z}{\sqrt{\chi^2_{n-2}/(n-2)}} = t_{n-2} \; \Box$$

\end{document}

% List of tex snippets:
%   - tex-header (this)
%   - R      --> \mathbb{R}
%   - Z      --> \mathbb{Z}
%   - B      --> \mathcal{B}
%   - E      --> \mathcal{E}
%   - M      --> \mathcal{M}
%   - m      --> \mathfrak{m}({#1})
%   - normlp --> \norm{{#1}}_{L^{{#2}}}
